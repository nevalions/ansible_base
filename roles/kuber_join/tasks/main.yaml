---
- name: Check if node is already joined
  ansible.builtin.stat:
    path: /etc/kubernetes/kubelet.conf
  register: kubelet_conf

- name: Fail if node is already joined
  ansible.builtin.fail:
    msg: "Node is already joined to a cluster. Use kuber_worker_reset.yaml to reset first."
  when: kubelet_conf.stat.exists

- name: Assert control plane inventory group exists when using VIP
  ansible.builtin.assert:
    that:
      - groups['planes_all'] is defined
      - groups['planes_all'] | length > 0
    success_msg: "Control plane inventory group found for VIP delegation"
    fail_msg: "VIP is set, but no control plane hosts found. Set kuber_join_control_plane_host to a control plane inventory host/group."
  when: kuber_join_control_plane_host == 'VIP'

- name: Set delegate host for control plane tasks
  ansible.builtin.set_fact:
    kuber_join_delegate_host: "{{ kuber_join_control_plane_ssh_host }}"

- name: Generate kubeadm join token from control plane
  ansible.builtin.command: kubeadm token create --print-join-command
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: join_command
  changed_when: true
  delegate_to: "{{ kuber_join_delegate_host }}"
  run_once: true
  check_mode: no

- name: Parse join command to extract token and CA cert hash
  ansible.builtin.set_fact:
    join_command_parts: "{{ join_command.stdout | regex_replace('kubeadm join ', '') | regex_replace('--discovery-token-ca-cert-hash ', '') | split(' ') }}"
    kuber_join_token: "{{ join_command.stdout | regex_search('--token\\s+[a-z0-9]+\\.[a-z0-9]+') | regex_replace('--token\\s+', '') }}"
    kuber_join_ca_cert_hash: "{{ join_command.stdout | regex_search('sha256:[a-f0-9]{64}') | regex_replace('sha256:', '') }}"

- name: Display join information
  ansible.builtin.debug:
    msg:
      - "Control Plane: {{ kuber_join_control_plane_ip }}"
      - "Token: {{ kuber_join_token }}"
      - "CA Cert Hash: sha256:{{ kuber_join_ca_cert_hash }}"

- name: Copy kubeadm join config
  ansible.builtin.template:
    src: kube-join.yaml.j2
    dest: /tmp/kube-join.yaml
    mode: "0644"

- name: Install base CNI plugin package on Debian
  ansible.builtin.apt:
    name: containernetworking-plugins
    state: present
    update_cache: true
  when: ansible_os_family == 'Debian'

- name: Ensure CNI plugin directory exists
  ansible.builtin.file:
    path: /opt/cni/bin
    state: directory
    mode: "0755"

- name: Discover base CNI plugin binaries
  ansible.builtin.find:
    paths: /usr/lib/cni
    file_type: file
  register: kuber_join_base_cni_plugins
  when: ansible_os_family == 'Debian'

- name: Copy base CNI plugins to runtime directory
  ansible.builtin.copy:
    src: "{{ item.path }}"
    dest: "/opt/cni/bin/{{ item.path | basename }}"
    mode: "0755"
    remote_src: true
  loop: "{{ kuber_join_base_cni_plugins.files | default([]) }}"
  when: ansible_os_family == 'Debian'

- name: Verify loopback CNI plugin exists
  ansible.builtin.stat:
    path: /opt/cni/bin/loopback
  register: kuber_join_loopback_plugin

- name: Assert loopback CNI plugin is present
  ansible.builtin.assert:
    that:
      - kuber_join_loopback_plugin.stat.exists
    fail_msg: "CNI loopback plugin missing at /opt/cni/bin/loopback; worker join will fail for sandbox networking."
    success_msg: "CNI loopback plugin is present"

- name: Wait for flannel DaemonSet rollout on control plane before join
  ansible.builtin.command: >-
    kubectl rollout status daemonset/{{ kuber_join_cni_daemonset_name }}
    -n {{ kuber_join_cni_namespace }} --timeout=120s
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  when:
    - kuber_join_cni_type == 'flannel'
    - kuber_join_cni_flannel_readiness_check | bool

- name: Wait for flannel pods to be Ready before join
  ansible.builtin.command: >-
    kubectl wait pod -l {{ kuber_join_cni_label_selector }}
    -n {{ kuber_join_cni_namespace }}
    --for=condition=ready --timeout=120s
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  when:
    - kuber_join_cni_type == 'flannel'
    - kuber_join_cni_flannel_readiness_check | bool

- name: Check for stale cni0 interface
  ansible.builtin.command: ip link show cni0
  register: kuber_join_cni0_interface
  changed_when: false
  failed_when: false

- name: Check for stale flannel.1 interface
  ansible.builtin.command: ip link show flannel.1
  register: kuber_join_flannel_interface
  changed_when: false
  failed_when: false

- name: Fail when stale CNI interfaces are present before join
  ansible.builtin.fail:
    msg: >-
      Stale CNI interfaces detected before join
      (cni0={{ 'present' if kuber_join_cni0_interface.rc == 0 else 'absent' }},
      flannel.1={{ 'present' if kuber_join_flannel_interface.rc == 0 else 'absent' }}).
      Run kuber_worker_reset.yaml for this node, verify interfaces are gone, then retry kuber_worker_join.yaml.
  when:
    - kuber_join_cni0_interface.rc == 0 or kuber_join_flannel_interface.rc == 0

- name: Check listeners on MetalLB memberlist port before join
  ansible.builtin.shell: ss -H -ltnup '( sport = :7946 )' || true
  register: kuber_join_memberlist_listeners
  changed_when: false
  failed_when: false

- name: Fail when MetalLB memberlist port is already in use
  ansible.builtin.fail:
    msg: >-
      Port 7946 is already in use before join; MetalLB speaker will fail to bind memberlist.
      Listener(s): {{ kuber_join_memberlist_listeners.stdout_lines | join('; ') }}.
      Run kuber_worker_reset.yaml for this node or stop the conflicting daemon, then retry kuber_worker_join.yaml.
  when: kuber_join_memberlist_listeners.stdout_lines | length > 0

- name: Ensure kubelet service is enabled and started (required for kubeadm join)
  ansible.builtin.systemd:
    name: kubelet
    enabled: true
    state: started
  when: not ansible_check_mode

- name: Join worker node to cluster
  ansible.builtin.command: kubeadm join --config=/tmp/kube-join.yaml
  register: kubeadm_join
  changed_when: true
  when: not ansible_check_mode

- name: Wait for kubelet to be ready
  ansible.builtin.command: systemctl is-active kubelet
  register: kubelet_status
  until: kubelet_status.rc == 0
  retries: 10
  delay: 5
  changed_when: false

- name: Check kubelet is enabled
  ansible.builtin.command: systemctl is-enabled kubelet
  register: kubelet_enabled
  changed_when: false
  failed_when: false

- name: Assert kubelet is enabled
  ansible.builtin.assert:
    that:
      - kubelet_enabled.rc == 0
      - (kubelet_enabled.stdout | trim) == 'enabled'
    success_msg: "Kubelet service is enabled"
    fail_msg: "Kubelet service is not enabled (systemctl is-enabled kubelet: {{ kubelet_enabled.stdout | default('') | trim }})"

- name: Display join success message
  ansible.builtin.debug:
    msg: "Node {{ inventory_hostname }} successfully joined to cluster"

- name: Verify node is visible from control plane
  ansible.builtin.command: kubectl get nodes {{ ansible_facts['hostname'] }}
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: node_check
  delegate_to: "{{ kuber_join_delegate_host }}"
  run_once: true
  changed_when: false
  ignore_errors: true

- name: Display node status
  ansible.builtin.debug:
    var: node_check.stdout_lines
  when: node_check.rc == 0

- name: Wait for node to be Ready
  ansible.builtin.command: kubectl wait --for=condition=ready node {{ ansible_facts['hostname'] }} --timeout=600s
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: node_ready
  delegate_to: "{{ kuber_join_delegate_host }}"
  run_once: true
  changed_when: false
  until: node_ready.rc == 0
  retries: 30
  delay: 10
  ignore_errors: true

- name: Assert node is Ready
  ansible.builtin.assert:
    that:
      - node_ready.rc == 0
    success_msg: "Worker node {{ ansible_facts['hostname'] }} is Ready"
    fail_msg: "Worker node {{ ansible_facts['hostname'] }} is not Ready after 600s"
  when: node_ready.rc is defined

- name: Discover kube-dns service cluster IP for post-join probe
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - kube-system
      - get
      - svc
      - kube-dns
      - -o
      - jsonpath={.spec.clusterIP}
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_kube_dns_ip
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  when: kuber_join_node_dns_probe_enabled | bool

- name: Assert kube-dns service IP discovered for post-join probe
  ansible.builtin.assert:
    that:
      - kuber_join_kube_dns_ip.stdout | default('') | length > 0
    fail_msg: "Could not discover kube-dns ClusterIP in kube-system namespace"
    success_msg: "kube-dns ClusterIP discovered: {{ kuber_join_kube_dns_ip.stdout }}"
  when: kuber_join_node_dns_probe_enabled | bool

- name: Set post-join DNS probe pod names
  ansible.builtin.set_fact:
    kuber_join_dns_probe_pod: "join-dns-probe-{{ ansible_facts['hostname'] | lower | regex_replace('[^a-z0-9-]', '-') | truncate(35, true, '') }}"
    kuber_join_dns_probe_pod_retry: "join-dns-retry-{{ ansible_facts['hostname'] | lower | regex_replace('[^a-z0-9-]', '-') | truncate(35, true, '') }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_kube_dns_ip.stdout | default('') | length > 0

- name: Delete stale post-join DNS probe pod
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - delete
      - pod
      - "{{ kuber_join_dns_probe_pod }}"
      - --ignore-not-found=true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  failed_when: false
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_kube_dns_ip.stdout | default('') | length > 0

- name: Run post-join DNS probe on joined node
  ansible.builtin.command:
    argv:
      - kubectl
      - run
      - "{{ kuber_join_dns_probe_pod }}"
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - --image={{ kuber_join_node_dns_probe_image }}
      - --restart=Never
      - --overrides={"spec":{"nodeName":"{{ ansible_facts['hostname'] }}","terminationGracePeriodSeconds":0}}
      - --command
      - --
      - sh
      - -c
      - nslookup {{ kuber_join_node_dns_probe_domain }} {{ kuber_join_kube_dns_ip.stdout }} >/dev/null
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_dns_probe_create
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: true
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_kube_dns_ip.stdout | default('') | length > 0

- name: Wait for post-join DNS probe completion
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - get
      - pod
      - "{{ kuber_join_dns_probe_pod }}"
      - -o
      - jsonpath={.status.phase}
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_dns_probe_phase
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  until:
    - kuber_join_dns_probe_phase.stdout in ['Succeeded', 'Failed']
  retries: "{{ kuber_join_node_dns_probe_retries }}"
  delay: "{{ kuber_join_node_dns_probe_delay }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_kube_dns_ip.stdout | default('') | length > 0

- name: Set initial post-join DNS probe status
  ansible.builtin.set_fact:
    kuber_join_node_dns_failed: "{{ kuber_join_dns_probe_phase.stdout != 'Succeeded' }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_dns_probe_phase is defined

- name: Recycle kube-proxy on joined node when DNS probe fails
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - kube-system
      - delete
      - pod
      - -l
      - k8s-app=kube-proxy
      - --field-selector
      - spec.nodeName={{ ansible_facts['hostname'] }}
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_kube_proxy_restart
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: true
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_failed | default(false)

- name: Wait after kube-proxy recycle
  ansible.builtin.pause:
    seconds: 20
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_failed | default(false)

- name: Delete stale retry DNS probe pod
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - delete
      - pod
      - "{{ kuber_join_dns_probe_pod_retry }}"
      - --ignore-not-found=true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  failed_when: false
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_failed | default(false)

- name: Re-run DNS probe after kube-proxy recycle
  ansible.builtin.command:
    argv:
      - kubectl
      - run
      - "{{ kuber_join_dns_probe_pod_retry }}"
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - --image={{ kuber_join_node_dns_probe_image }}
      - --restart=Never
      - --overrides={"spec":{"nodeName":"{{ ansible_facts['hostname'] }}","terminationGracePeriodSeconds":0}}
      - --command
      - --
      - sh
      - -c
      - nslookup {{ kuber_join_node_dns_probe_domain }} {{ kuber_join_kube_dns_ip.stdout }} >/dev/null
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_dns_probe_create_retry
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: true
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_failed | default(false)

- name: Wait for retry DNS probe completion
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - get
      - pod
      - "{{ kuber_join_dns_probe_pod_retry }}"
      - -o
      - jsonpath={.status.phase}
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: kuber_join_dns_probe_phase_retry
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  until:
    - kuber_join_dns_probe_phase_retry.stdout in ['Succeeded', 'Failed']
  retries: "{{ kuber_join_node_dns_probe_retries }}"
  delay: "{{ kuber_join_node_dns_probe_delay }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_failed | default(false)

- name: Set final post-join DNS probe status
  ansible.builtin.set_fact:
    kuber_join_node_dns_failed: "{{ kuber_join_dns_probe_phase_retry.stdout != 'Succeeded' }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - kuber_join_node_dns_auto_repair | bool
    - kuber_join_node_dns_probe_phase_retry is defined

- name: Clean up post-join DNS probe pods
  ansible.builtin.command:
    argv:
      - kubectl
      - -n
      - "{{ kuber_join_node_dns_probe_namespace }}"
      - delete
      - pod
      - "{{ item }}"
      - --ignore-not-found=true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  changed_when: false
  failed_when: false
  loop:
    - "{{ kuber_join_dns_probe_pod | default('') }}"
    - "{{ kuber_join_dns_probe_pod_retry | default('') }}"
  when:
    - kuber_join_node_dns_probe_enabled | bool
    - item | length > 0

- name: Assert node-local DNS is healthy after join
  ansible.builtin.assert:
    that:
      - not (kuber_join_node_dns_failed | default(false))
    success_msg: "Joined node {{ ansible_facts['hostname'] }} passed node-local DNS probe"
    fail_msg: >-
      Joined node {{ ansible_facts['hostname'] }} failed node-local DNS probe for
      {{ kuber_join_node_dns_probe_domain }} via kube-dns {{ kuber_join_kube_dns_ip.stdout | default('unknown') }}.
      You can repair without SSH by running:
      kubectl -n kube-system delete pod -l k8s-app=kube-proxy --field-selector spec.nodeName={{ ansible_facts['hostname'] }}
  when:
    - kuber_join_node_dns_probe_enabled | bool

- name: Label worker node role
  ansible.builtin.command: kubectl label node {{ ansible_facts['hostname'] }} node-role.kubernetes.io/worker= --overwrite
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  delegate_to: "{{ kuber_join_delegate_host }}"
  run_once: true
  changed_when: true
  ignore_errors: true
  when: not ansible_check_mode

- name: Get CNI pods
  ansible.builtin.command: >-
    kubectl get pods -n {{ kuber_join_cni_namespace }}
    -l {{ kuber_join_cni_label_selector }} -o wide
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  register: cni_pod_check
  delegate_to: "{{ kuber_join_delegate_host }}"
  run_once: true
  changed_when: false
  ignore_errors: true

- name: Display CNI pods
  ansible.builtin.debug:
    var: cni_pod_check.stdout_lines
  when: cni_pod_check.rc == 0

- name: Display worker join summary
  ansible.builtin.debug:
    msg:
      - "=== Worker Join Complete ==="
      - "Node: {{ ansible_facts['hostname'] }}"
      - "Status: Ready"
      - "CNI: {{ kuber_join_cni_type }}"
      - "Next step: Run kuber_verify.yaml for full cluster health check"
